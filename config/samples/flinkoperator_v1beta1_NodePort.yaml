# Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: flinkoperator.k8s.io/v1beta1
kind: FlinkCluster
metadata:
  name: savepoint
spec:
  image:
    name: hub.c.163.com/flink/flink:1.9.1
  jobManager:
    accessScope: NodePort
    ports:
      ui: 8081
      rpc: 6123
    resources:
      limits:
        memory: "1024Mi"
        cpu: "200m"
    volumes:
    - name: consumerdata-sloth
      emptyDir: {}
    volumeMounts:
    - mountPath: /opt/flink/log
      name: consumerdata-sloth
  taskManager:
    replicas: 2
    resources:
      limits:
        memory: "1024Mi"
        cpu: "200m"
    volumes:
    - name: consumerdata-sloth
      emptyDir: {}
    volumeMounts:
    - mountPath: /opt/flink/log
      name: consumerdata-sloth
  job:
    jarFile: hdfs://slothTest/sloth/kafkaDemo19-1.0-SNAPSHOT.jar
    className: com.netease.java.KafkaExample
    args: ["--input-topic", "k8s-test-data","--bootstrap.servers","10.194.106.141:9094,10.194.106.6:9094,10.194.106.3:9094",
           "--group.id","produce-data-1","--output-topic", "k8s-test-output"]
    parallelism: 2
    volumes:
    - name: consumerdata-sloth
      emptyDir: {}
    volumeMounts:
    - mountPath: /opt/flink/log
      name: consumerdata-sloth
    restartPolicy: FromSavepointOnFailure
    savepointsDir: hdfs://slothTest/user/sloth/savepoint
    fromSavePoint: hdfs://slothTest/user/sloth/savepoint/savepoint-95ea29-be2abc755fb6
    allowNonRestoredState: false
  flinkProperties:
    taskmanager.numberOfTaskSlots: "1"
    high-availability: zookeeper
    high-availability.zookeeper.quorum: sloth-test0.dg.163.org:2181,sloth-test1.dg.163.org:2181,sloth-test2.dg.163.org:2181
    high-availability.storageDir: hdfs://slothTest/user/sloth/HA/
    high-availability.cluster-id: "savepoint"
    high-availability.jobmanager.port: "6123"
    high-availability.zookeeper.path.root: /sloth-flink-k8s
    restart-strategy: failure-rate
    restart-strategy.failure-rate.max-failures-per-interval: "5000"
    restart-strategy.failure-rate.failure-rate-interval: 6 min
    restart-strategy.failure-rate.delay: 1 s
    state.backend: rocksdb
    state.backend.incremental: "true"
    #filesystem to store checkpoint meta data (when external checkpoint enabled.)
    state.checkpoints.dir: hdfs://slothTest/user/sloth/sloth-fs-checkpoints/meta/1_7
    #filesystem to store checkpoint data
    state.backend.fs.checkpointdir: hdfs://slothTest/user/sloth/sloth-fs-checkpoints/cpk/1_7
    state.backend.rocksdb.localdir: /opt/flink/data
    metrics.reporters: influxdb
    metrics.reporter.influxdb.class: org.apache.flink.metrics.influxdb.InfluxdbReporter
    metrics.reporter.influxdb.host: sloth-tsdb0.dg.163.org,sloth-tsdb1.dg.163.org,sloth-tsdb2.dg.163.org
    metrics.reporter.influxdb.port: "8091"
    metrics.reporter.influxdb.db: flink-test-V2
    metrics.reporter.influxdb.username: flink-metrics
    metrics.reporter.influxdb.password: sloth1234
    metrics.reporter.influxdb.connectTimeout: "100000"
    metrics.reporter.influxdb.writeTimeout: "10000"
    metrics.reporter.influxdb.consistency: ANY
